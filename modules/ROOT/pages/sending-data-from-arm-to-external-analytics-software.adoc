= Export Data to External Analytics Tools (Hybrid)
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]


image:logo-cloud-disabled.png[link="/runtime-manager/deployment-strategies#cloudhub", title="CloudHub"]
image:logo-hybrid-active.png[link="/runtime-manager/deployment-strategies#hybrid", title="Hybrid"]
image:logo-server-active.png[link="/runtime-manager/deployment-strategies#anypoint-platform-private-cloud-edition", title="Anypoint Platform PCE"]
image:logo-rtf-disabled.png[link="/runtime-manager/deployment-strategies#anypoint-runtime-fabric", title="Runtime Fabric"]


To send the event notifications of your Mule applications to a third-party tool such as Splunk and ELK, configure Runtime Manager to export data to external analytics tools.

If you intend to export your payload's contents to be logged, keep in mind that not all formats can be exported. See xref:about-logging-of-payload-formats.adoc[Payload Formats and Logging].

Applications that you deploy on-premises or to cloud servers can be integrated into third-party analytics applications, which is what this document describes.


You can configure the Runtime Manager to send out Mule events to external software, this includes flow executions, exceptions raised, etc.
This works with apps deployed to any runtime, and for both the Runtime Manager in the cloud and the Runtime Manager that comes bundled with the xref:1.5@private-cloud::index.adoc[Anypoint Platform Private Cloud Edition].


If you deploy apps from Runtime Manager to customer-managed Mule servers, you can send your Mule app event and analytics data to third party analytics software such as Elk and Splunk.

Sending data to third party software is currently not available (out of the box) for applications on xref:cloudhub.adoc[CloudHub].
One way to achieve this is by using the https://docs.mulesoft.com/runtime-manager/custom-log-appender[CloudHub custom log appender].

Integration between Runtime Manager and third-party analytics software looks like this:

image::amc-onprem-diagram-detail.jpg[]

The xref:runtime-manager-agent.adoc[Runtime Manager agent] acts in between Runtime Manager and the third party software. The agent enables integration and sends event notifications to your third party analytics tool.

== Prerequisites

* Mule 3.6 or later
* API gateway standalone version 2.1.0 or later
* Runtime Manager agent 1.2.0 or later
+
Runtime Manager agent 1.3.1 is required to send data to Splunk using the HTTP Event Collector or over TCP.
+
For information about updating the agent, see xref:installing-and-configuring-runtime-manager-agent.adoc[Install or Update the Runtime Manager Agent].

* To send data to Splunk using the HTTP Event Collector, you must first set up a data input and obtain a token from Splunk:
+
.. Sign in to your Splunk account.
.. Navigate to *Settings* -> *Data Inputs*.
.. For the *HTTP Event Collector* type, click *Add new*.
// image::splunk-datainput-setup.png[Splunk settings]
.. Follow the steps to set up a data input and obtain the token.

* To send data to Splunk over TCP, you must first enable the input source in Splunk:
+
.. Sign in to your Splunk account.
.. Navigate to *Settings* -> *Data Inputs*.
.. For the *TCP* type, click *Add new*.
// image::splunk-datainput-setup-tcp.png[splunk settings]
.. Follow the steps to set up a data input.


== Integrate with Splunk

With http://www.splunk.com/[Splunk], you can capture and index Mule event notification data into a searchable repository from which you can then generate graphs, reports, alerts, dashboards and visualizations.

image::amc-onprem-diagram-detail-splunk.jpg[]

To integrate with Splunk, you must configure a new source type on your Splunk instance with the correct configuration to parse the HTTP events sent from the API gateway.

. If necessary, create the `$SPLUNK_HOME/opt/splunk/etc/system/local/props.conf` file.
. Append the following source type to the `props.conf` file:
+
[source,yaml,linenums]
----
[mule]
TRUNCATE = 0
LINE_BREAKER = ([\r\n]+)
SHOULD_LINEMERGE = false
INDEXED_EXTRACTIONS = JSON
KV_MODE = JSON
category = Mule Splunk Integration
description = Mule Agent event information
----

. Restart your Splunk instance for your changes to take effect.

.Configurable Fields
|===
|Field|Data Type|Description|Type|Default Value

|`user`
|String
|Username to connect to Splunk.
|Required
|

|`pass`
|String
|The password of the Splunk user.
|Required
|

|`host`
|String
|IP or hostname of the server where Splunk is running.
|Required
|

|`port`
|int
|Splunk management port.
|Optional
|8089

|`scheme`
|String
|Scheme of connection to the Splunk management port. Possible values: http, https.
|Optional
|https

|`sslSecurityProtocol`
|String
|SSL Security Protocol to use in the https connection. Possible values: TLSv1_2, TLSv1_1, TLSv1, SSLv3.
|Optional
|TLSv1_2

|`splunkIndexName`
|String
|Splunk index name where all the events must be sent. If the user has the rights,
and the index doesn't exist, then the internal handler will create it.
|Optional
|main

|`splunkSource`
|String
|The source used on the events sent to Splunk.
|Optional
|mule

|`splunkSourceType`
|String
|The sourcetype used on the events sent to Splunk.
|Optional
|mule

|`dateFormatPattern`
|String
|Date format used to format the timestamp.
|Optional
|yyyy-MM-dd'T'HH:mm:ssSZ

|===

.Splunk Internal Handler Minimum Configuration Example
[source,yaml]
----
  mule.agent.gw.http.handler.splunk:
    host: 192.168.61.131
    user: admin
    pass: test
----

=== Send Data to Splunk

. If you plan to send data to Splunk using the HTTP Event Collector or over TCP, check the <<Prerequisites>>.
. From Anypoint Platform, select *Runtime Manager*.
. Click the *Servers* tab.
. Click the *Type* column to display the details pane for the server to configure.
. Click *Manage Server*.
. Click the *Plugins* tab:
+
.The screenshot shows (*1*) the *Splunk* option, (*2*) the *Level* menu, and (*3*) the gear icon on the server *Plugins* tab.
image::hybrid-export-splunk.png[Splunk option, Level menu, and gear icon on the server Plugins tab.]

. Under *Event Tracking*, enable *Splunk*.
. Select the type of of information to send from the *Level* menu:
+
Business Events::
Flow start/end, async messages, exceptions, and custom events
Tracking::
Business Events plus exception strategy, and endpoint messages
Debug::
Tracking plus message processor begin/end
. Click the gear icon to specify your Splunk configuration:
+
.The screenshot shows (*1*) the protocol option, (*2*) the date input types, and (*3*) the *Show more options* switch in the Splunk configuration window.
image::hybrid-export-splunk-configure.png[Protocol option, data input types, and Show more options switch in the Splunk configuration window]
. Specify the host (IP address or hostname) and management port of the server where Splunk is running. 
+
* To send data to Splunk using the REST API, select *Rest API* and enter the username and password for your Splunk account.
* To send data to Splunk using the HTTP Event Collector, select *HTTP Event Collector* and paste the token from Splunk in the *Token* field:
+
.The screenshot shows (*1*) the HTTP Event Collector option and (*2*) the *Token* field in the Splunk configuration window.
image::hybrid-export-splunk-configure-http.png[HTTP Event Collector option and Token field in the Splunk configuration window]

* To send data to Splunk over TCP, select *tcp* from the menu and enter the username and password for your Splunk account.
. If you want, you can specify formatting properties for the sent data:
+
.The arrow shows the *SSL Protocol* option in the Splunk configuration window.
image::hybrid-export-splunk-configure-advanced.png[SSL Protocol option in the Splunk configuration window]
+
[NOTE]
The *SSL Protocol* option applies only to the REST API data input type.
+
If you set values for the Splunk index, Splunk source, and Splunk source type when registering your data input in your Splunk account, any values you enter overwrite those values.


== Integrate with an ELK Stack

ELK combines three open source tools (Elasticsearch, Logstash, Kibana) that work together to help you store, search and analyze log data. You can output the Mule event notifications as generic system logs, which can be handled by your ELK stack. Logstash captures and indexes the data into the log, from which you can then use Elasticsearch and Kibana to generate graphs, reports, alerts, dashboards and visualizations.
The Runtime Manager agent helps you store all of the Event Notifications produced from the Mule runtime flows into a configurable log file with a rolling file policy.

image::amc-onprem-diagram-detail-elk.jpg[]

To direct information to the folder where your ELK stack reads from, you must do the following:


. From Anypoint Platform, select *Runtime Manager*.
. Click the *Servers* tab.
. Click the *Type* column to display the details pane for the server to configure.
. Click *Manage Server*.
. Click the *Plugins* tab:
+
image::hybrid-export-splunk.png[]

. Select the type of of information to send from the *Level* menu:
+
Business Events::
Flow start/end, async messages, exceptions, and custom events
Tracking::
Business Events plus exception strategy, and endpoint messages
Debug::
Tracking plus message processor begin/end.
. Under *Event Tracking*, enable *ELK*.
. Click the gear icon to enter your ELK configuration:
+
image::hybrid-export-splunk-configure.png[]



. On the *Event Tracking* region, activate the *ELK* switch. This will open a pop up menu where you can provide the address to the folder where you keep the log files that your ELK stack reads.
+
image::sending-data-from-arm-to-external-monitoring-software-elk.png[]

. Optionally, you can open the advanced menu and set up certain formatting properties of the data you send out and how the information is archived.
+
image::elk-config-advanced.jpg[ELK advanced]


== Configure API Analytics

Before you can set up the connection to external software through the Runtime Manager UI, you must first make some changes to API Gateway to prepare it for this.

. In your API gateway standalone directory, open the `conf/wrapper.conf` file.
. Ensure that the following property is set to `true` and that the line is uncommented:
+
[source,java,linenums]
----
wrapper.java.additional.<n>=-Danypoint.platform.analytics_enabled=true
----

. Look for this other line:
+
[source,java,linenums]
----
wrapper.java.additional.<n>=-Danypoint.platform.analytics_base_uri=https://analytics-ingest.anypoint.mulesoft.com
----
. Remove the URL in it, so that it looks like this:
+
[source,java,linenums]
----
wrapper.java.additional.<n>=-Danypoint.platform.analytics_base_uri=
----
. When using Anypoint Platform Private Cloud Edition, there's one more parameter you need to change:
+
[source,java,linenums]
----
wrapper.java.additional.<n>=-Danypoint.platform.on_prem=true
----
+
`anypoint.platform.on_prem` is set to `false` by default. To manage it through Anypoint Platform Private Cloud Edition, you must set it to `true`. To manage it through the Runtime Manager in the cloud, leave it as `false`.

[TIP]
Note that in the above code snippets, when lines that contain `.<n>`, that should be replaced with an integer number that is unique within the wrapper.

After you set up your standalone API gateway, the steps for connecting to Splunk and ELK are identical to those when dealing with Mule Custom Events, except that you should set them up via the corresponding switches.

image::sending-data-from-arm-to-external-monitoring-software-api-analytics.png[]

[NOTE]
--
Starting from Mule versions 4.2.0 and 3.9.3, you can configure the Mule runtime engine to forward events to both a third-party system, like ELK and Splunk, and to Anypoint Platform by adding an additional property to the `wrapper.conf` file:

[source,java,linenums]
----
wrapper.java.additional.<n>=-Danypoint.platform.analytics_multiple_consumers_enabled=true
----
--

[WARNING]
If you modify your `wrapper.conf` file as described above but don't assign an external destination for your data (as you can do via the Runtime Manager UI), then this analytics data will be stored in a queue in the server where the API gateway is being run and could pile up to the point of crashing the system.


=== Integrate API Analytics with Splunk and ELK

After you've configured your API gateway, you can now return to Runtime Manager and see that your servers have some additional options in their menu.

image::sending-data-from-arm-to-external-monitoring-software-api-analytics.png[]

You can now set up the sending of API analytics to both Splunk and ELK, you configure exactly in the same way as you do when sending business events to them. See <<Integrating with an ELK Stack, Integrating with an ELK Stack>> and <<Integrating with Splunk, Integrating with Splunk>>.


== See Also

* xref:rtm-agent-proxy-config#encrypt_password[Include an Encrypted Password in the mule-agent.yml File]
* xref:managing-servers.adoc[Servers, Server Groups, and Clusters]
* xref:monitoring.adoc[Monitoring Applications and Servers]
* xref:deploying-to-your-own-servers.adoc[Deploying to Your Servers]
* xref:managing-deployed-applications.adoc[Manage Deployed Applications]
* xref:managing-applications-on-your-own-servers.adoc[Managing Applications on Your Servers]
* https://anypoint.mulesoft.com/exchange/portals/anypoint-platform/f1e97bc6-315a-4490-82a7-23abe036327a.anypoint-platform/arm-rest-services[Runtime Manager REST API]
